
Consider a vector $\boldsymbol{v}\in\mathbb{C}^{m}$ and define subspaces
\begin{displaymath}
\mathcal{M}_{i} = \left\lbrace \boldsymbol{x}_{i,j} \triangleq Z_{i,2}^{j-1}\,Z_{i,1}\,\boldsymbol{v}: j\in\lbrace1,\ldots,m_{i}\rbrace\right\rbrace, \quad i\in \lbrace 1,\ldots,\nu \rbrace
\end{displaymath}
where $dim(\mathcal{M}_{i})=m_{i}$; moreover, vectors $\boldsymbol{x}_{i,j}$ are
linearly independent, therefore $\mathcal{M}_{q}\cap\mathcal{M}_{w}=\emptyset$
if $q\neq w$, and satisfy the recurrence relation
\begin{displaymath}
\begin{split}
\boldsymbol{x}_{i,j+1} &= Z_{i,2}^{j}\,Z_{i,1}\,\boldsymbol{v} = Z_{i,2}\,Z_{i,2}^{j-1}\,Z_{i,1}\,\boldsymbol{v} =  Z_{i,2}\,\boldsymbol{x}_{i,j}=A\,\boldsymbol{x}_{i,j} - \lambda_{i}\,\boldsymbol{x}_{i,j}, \quad j\in \lbrace 1,\ldots,m_{i}-1 \rbrace  \\
Z_{i,2}\,\boldsymbol{x}_{i,m_{i}} &=  Z_{i,2}\,Z_{i,2}^{m_{i}-1}\,Z_{i,1}\,\boldsymbol{v} = Z_{i,2}^{m_{i}}\,Z_{i,1}\,\boldsymbol{v} = \boldsymbol{0},\quad Z_{i,2}^{m_{i}}=O
\end{split}
\end{displaymath}
or rather
\begin{displaymath}
\begin{split}
A\,\boldsymbol{x}_{i,j} &= \lambda_{i}\,\boldsymbol{x}_{i,j} + \boldsymbol{x}_{i,j+1} , \quad j\in \lbrace 1,\ldots,m_{i}-1 \rbrace  \\
A\,\boldsymbol{x}_{i,m_{i}} &= \lambda_{i}\,\boldsymbol{x}_{i,m_{i}} \\
\end{split}
\end{displaymath}
which can be rewritten in matrix notation as $A\,X_{i} = X_{i}\,J_{i}$ where
\begin{displaymath}
X_{i} = \left[\boldsymbol{x}_{i,1},\ldots,\boldsymbol{x}_{i,m_{i}} \right]\in\mathcal{C}^{m\times m_{i}} \quad\quad
J_{i} = \left[ \begin{array}{cccc}
    \lambda_{i} \\
    1 & \lambda_{i} \\
      & \ddots & \ddots \\
      & & 1 &\lambda_{i} \\
\end{array} \right] \in\mathcal{C}^{m_{i}\times m_{i}}
\end{displaymath}
Under this point of view, vectors $\boldsymbol{x}_{i,j}$, $j\in \lbrace
1,\ldots,m_{i} \rbrace$, are called \textit{generalized eigenvectors}
($\boldsymbol{x}_{i,m_{i}}$ is an eigenvector, as usual) relative
to the eigenvalue $\lambda_{i}$ of matrix $A$; moreover, $J_{i}$ is called
\textit{Jordan block}, for $i\in \lbrace 1,\ldots,\nu \rbrace$. 

Generalizing previous arguments, the \textit{Jordan normal form} of $A$ is
defined by the relation $A\,X = X\, J$, where
\begin{displaymath}
X = \left[X_{1},\ldots,X_{\nu} \right]\in\mathcal{C}^{m\times m} \quad\quad
J = \left[ \begin{array}{ccc}
    J_{1} \\
      & \ddots \\
      & & J_{\nu} \\
\end{array} \right] \in\mathcal{C}^{m\times m}
\end{displaymath}
with respect to vector $\boldsymbol{v}\in\mathcal{C}^{m}$ which defines
subspaces $\mathcal{M}_{i}$, for $i\in \lbrace 1,\ldots,\nu \rbrace$; finally,
if $X$ is non-singular then matrices $A$ and $X^{-1}\,A\,X = J$ are
    \textit{similar}, $A \sim_{X} J$ in symbols. All this derivations allow us
    to compute functions of matrices in a easier way, namely $f(A)$ can be
    computed as follows
\begin{displaymath}
\begin{split}
&X^{-1}\,A\,X = J\\
&f(X^{-1}\,A\,X) = f(J)\\
&X^{-1}\,f(A)\,X = f(J)\\
&f(A) = X\,f(J)\,X^{-1}\\
\end{split}
\end{displaymath}
provided that $A \sim_{X} J$; in words, first find matrices $X$ and $J$, second
apply $f(J)$, third multiply on both sides. Of these steps remain to
investigate the application of $f$ to $J$, which is our next task.

Since matrix $J$ is a $m$-minor of the Riordan array $\left(1+t, t\right)$ then
it shares the same base of polynomials $\Phi_{1, j}$, for
$j\in\lbrace1,\ldots,m_{1} \rbrace$, as all other Riordan arrays do; moreover,
$\lambda_{1}=1$ with algebraic multiplicity $m_{1}=m$. For a function $f$
defined on $\sigma(J)$, the application $f(J)$ produces the matrix
\begin{displaymath}
f{\left (J \right )} = \left[\begin{matrix}f{\left (\lambda_{1} \right )} & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\frac{d}{d \lambda_{1}} f{\left (\lambda_{1} \right )} & f{\left (\lambda_{1} \right )} & 0 & 0 & 0 & 0 & 0 & 0\\\frac{1}{2} \frac{d^{2}}{d \lambda_{1}^{2}}  f{\left (\lambda_{1} \right )} & \frac{d}{d \lambda_{1}} f{\left (\lambda_{1} \right )} & f{\left (\lambda_{1} \right )} & 0 & 0 & 0 & 0 & 0\\\frac{1}{6} \frac{d^{3}}{d \lambda_{1}^{3}}  f{\left (\lambda_{1} \right )} & \frac{1}{2} \frac{d^{2}}{d \lambda_{1}^{2}}  f{\left (\lambda_{1} \right )} & \frac{d}{d \lambda_{1}} f{\left (\lambda_{1} \right )} & f{\left (\lambda_{1} \right )} & 0 & 0 & 0 & 0\\\frac{1}{24} \frac{d^{4}}{d \lambda_{1}^{4}}  f{\left (\lambda_{1} \right )} & \frac{1}{6} \frac{d^{3}}{d \lambda_{1}^{3}}  f{\left (\lambda_{1} \right )} & \frac{1}{2} \frac{d^{2}}{d \lambda_{1}^{2}}  f{\left (\lambda_{1} \right )} & \frac{d}{d \lambda_{1}} f{\left (\lambda_{1} \right )} & f{\left (\lambda_{1} \right )} & 0 & 0 & 0\\\frac{1}{120} \frac{d^{5}}{d \lambda_{1}^{5}}  f{\left (\lambda_{1} \right )} & \frac{1}{24} \frac{d^{4}}{d \lambda_{1}^{4}}  f{\left (\lambda_{1} \right )} & \frac{1}{6} \frac{d^{3}}{d \lambda_{1}^{3}}  f{\left (\lambda_{1} \right )} & \frac{1}{2} \frac{d^{2}}{d \lambda_{1}^{2}}  f{\left (\lambda_{1} \right )} & \frac{d}{d \lambda_{1}} f{\left (\lambda_{1} \right )} & f{\left (\lambda_{1} \right )} & 0 & 0\\\frac{1}{720} \frac{d^{6}}{d \lambda_{1}^{6}}  f{\left (\lambda_{1} \right )} & \frac{1}{120} \frac{d^{5}}{d \lambda_{1}^{5}}  f{\left (\lambda_{1} \right )} & \frac{1}{24} \frac{d^{4}}{d \lambda_{1}^{4}}  f{\left (\lambda_{1} \right )} & \frac{1}{6} \frac{d^{3}}{d \lambda_{1}^{3}}  f{\left (\lambda_{1} \right )} & \frac{1}{2} \frac{d^{2}}{d \lambda_{1}^{2}}  f{\left (\lambda_{1} \right )} & \frac{d}{d \lambda_{1}} f{\left (\lambda_{1} \right )} & f{\left (\lambda_{1} \right )} & 0\\\frac{1}{5040} \frac{d^{7}}{d \lambda_{1}^{7}}  f{\left (\lambda_{1} \right )} & \frac{1}{720} \frac{d^{6}}{d \lambda_{1}^{6}}  f{\left (\lambda_{1} \right )} & \frac{1}{120} \frac{d^{5}}{d \lambda_{1}^{5}}  f{\left (\lambda_{1} \right )} & \frac{1}{24} \frac{d^{4}}{d \lambda_{1}^{4}}  f{\left (\lambda_{1} \right )} & \frac{1}{6} \frac{d^{3}}{d \lambda_{1}^{3}}  f{\left (\lambda_{1} \right )} & \frac{1}{2} \frac{d^{2}}{d \lambda_{1}^{2}}  f{\left (\lambda_{1} \right )} & \frac{d}{d \lambda_{1}} f{\left (\lambda_{1} \right )} & f{\left (\lambda_{1} \right )}\end{matrix}\right]
\end{displaymath}
which is a \textit{Toeplitz} matrix, therefore definition of its first column
defines the entire matrix. We do so for the family of functions studied in
previous sections:
\begin{displaymath}
\begin{split}
J^{r} \boldsymbol{e}_{0} &= \left[\begin{matrix}\frac{{\left(r\right)}_{0} \lambda_{1}^{r}}{0!}\\\frac{{\left(r\right)}_{1}}{1!} \lambda_{1}^{r - 1}\\\frac{{\left(r\right)}_{2}}{2!} \lambda_{1}^{r - 2}\\\frac{{\left(r\right)}_{3}}{3!} \lambda_{1}^{r - 3}\\\frac{{\left(r\right)}_{4}}{4!} \lambda_{1}^{r - 4}\\\frac{{\left(r\right)}_{5}}{5!} \lambda_{1}^{r - 5}\\\frac{{\left(r\right)}_{6}}{6!} \lambda_{1}^{r - 6}\\\frac{{\left(r\right)}_{7}}{7!} \lambda_{1}^{r - 7}\end{matrix}\right]\quad
\frac{\boldsymbol{e}_{0}}{J} = \left[\begin{matrix}\frac{1}{\lambda_{1}}\\- \frac{1}{\lambda_{1}^{2}}\\\frac{1}{\lambda_{1}^{3}}\\- \frac{1}{\lambda_{1}^{4}}\\\frac{1}{\lambda_{1}^{5}}\\- \frac{1}{\lambda_{1}^{6}}\\\frac{1}{\lambda_{1}^{7}}\\- \frac{1}{\lambda_{1}^{8}}\end{matrix}\right]\quad
\sqrt{J} \boldsymbol{e}_{0} = \left[\begin{matrix}\sqrt{\lambda_{1}}\\\frac{1}{2 \sqrt{\lambda_{1}}}\\- \frac{1}{8 \lambda_{1}^{\frac{3}{2}}}\\\frac{1}{16 \lambda_{1}^{\frac{5}{2}}}\\- \frac{5}{128 \lambda_{1}^{\frac{7}{2}}}\\\frac{7}{256 \lambda_{1}^{\frac{9}{2}}}\\- \frac{21}{1024 \lambda_{1}^{\frac{11}{2}}}\\\frac{33}{2048 \lambda_{1}^{\frac{13}{2}}}\end{matrix}\right] \quad
e^{J \alpha} \boldsymbol{e}_{0} = \left[\begin{matrix}e^{\alpha \lambda_{1}}\\\alpha e^{\alpha \lambda_{1}}\\\frac{\alpha^{2}}{2} e^{\alpha \lambda_{1}}\\\frac{\alpha^{3}}{6} e^{\alpha \lambda_{1}}\\\frac{\alpha^{4}}{24} e^{\alpha \lambda_{1}}\\\frac{\alpha^{5}}{120} e^{\alpha \lambda_{1}}\\\frac{\alpha^{6}}{720} e^{\alpha \lambda_{1}}\\\frac{\alpha^{7}}{5040} e^{\alpha \lambda_{1}}\end{matrix}\right] \\
\log{\left (J \right )} \boldsymbol{e}_{0} &= \left[\begin{matrix}\log{\left (\lambda_{1} \right )}\\\frac{1}{\lambda_{1}}\\- \frac{1}{2 \lambda_{1}^{2}}\\\frac{1}{3 \lambda_{1}^{3}}\\- \frac{1}{4 \lambda_{1}^{4}}\\\frac{1}{5 \lambda_{1}^{5}}\\- \frac{1}{6 \lambda_{1}^{6}}\\\frac{1}{7 \lambda_{1}^{7}}\end{matrix}\right] \quad
\sin{\left (J \right )} \boldsymbol{e}_{0} = \left[\begin{matrix}\sin{\left (\lambda_{1} \right )}\\\cos{\left (\lambda_{1} \right )}\\- \frac{1}{2} \sin{\left (\lambda_{1} \right )}\\- \frac{1}{6} \cos{\left (\lambda_{1} \right )}\\\frac{1}{24} \sin{\left (\lambda_{1} \right )}\\\frac{1}{120} \cos{\left (\lambda_{1} \right )}\\- \frac{1}{720} \sin{\left (\lambda_{1} \right )}\\- \frac{1}{5040} \cos{\left (\lambda_{1} \right )}\end{matrix}\right] \quad
\cos{\left (J \right )} \boldsymbol{e}_{0} = \left[\begin{matrix}\cos{\left (\lambda_{1} \right )}\\- \sin{\left (\lambda_{1} \right )}\\- \frac{1}{2} \cos{\left (\lambda_{1} \right )}\\\frac{1}{6} \sin{\left (\lambda_{1} \right )}\\\frac{1}{24} \cos{\left (\lambda_{1} \right )}\\- \frac{1}{120} \sin{\left (\lambda_{1} \right )}\\- \frac{1}{720} \cos{\left (\lambda_{1} \right )}\\\frac{1}{5040} \sin{\left (\lambda_{1} \right )}\end{matrix}\right] \quad
\end{split}
\end{displaymath}

For the sake of clarity, computation of inverse of $\mathcal{P}$ can be found as 
\iffalse
\begin{displaymath}
\scriptsize
\left[\begin{matrix}\frac{1}{\lambda_{1}} & 0 & 0 & 0 & 0 & 0 & 0 & 0\\- \frac{1}{\lambda_{1}^{2}} & \frac{1}{\lambda_{1}} & 0 & 0 & 0 & 0 & 0 & 0\\- \frac{1}{\lambda_{1}^{2}} + \frac{2}{\lambda_{1}^{3}} & - \frac{2}{\lambda_{1}^{2}} & \frac{1}{\lambda_{1}} & 0 & 0 & 0 & 0 & 0\\- \frac{1}{\lambda_{1}^{2}} + \frac{6}{\lambda_{1}^{3}} - \frac{6}{\lambda_{1}^{4}} & - \frac{3}{\lambda_{1}^{2}} + \frac{6}{\lambda_{1}^{3}} & - \frac{3}{\lambda_{1}^{2}} & \frac{1}{\lambda_{1}} & 0 & 0 & 0 & 0\\- \frac{1}{\lambda_{1}^{2}} + \frac{14}{\lambda_{1}^{3}} - \frac{36}{\lambda_{1}^{4}} + \frac{24}{\lambda_{1}^{5}} & - \frac{4}{\lambda_{1}^{2}} + \frac{24}{\lambda_{1}^{3}} - \frac{24}{\lambda_{1}^{4}} & - \frac{6}{\lambda_{1}^{2}} + \frac{12}{\lambda_{1}^{3}} & - \frac{4}{\lambda_{1}^{2}} & \frac{1}{\lambda_{1}} & 0 & 0 & 0\\- \frac{1}{\lambda_{1}^{2}} + \frac{30}{\lambda_{1}^{3}} - \frac{150}{\lambda_{1}^{4}} + \frac{240}{\lambda_{1}^{5}} - \frac{120}{\lambda_{1}^{6}} & - \frac{5}{\lambda_{1}^{2}} + \frac{70}{\lambda_{1}^{3}} - \frac{180}{\lambda_{1}^{4}} + \frac{120}{\lambda_{1}^{5}} & - \frac{10}{\lambda_{1}^{2}} + \frac{60}{\lambda_{1}^{3}} - \frac{60}{\lambda_{1}^{4}} & - \frac{10}{\lambda_{1}^{2}} + \frac{20}{\lambda_{1}^{3}} & - \frac{5}{\lambda_{1}^{2}} & \frac{1}{\lambda_{1}} & 0 & 0\\- \frac{1}{\lambda_{1}^{2}} + \frac{62}{\lambda_{1}^{3}} - \frac{540}{\lambda_{1}^{4}} + \frac{1560}{\lambda_{1}^{5}} - \frac{1800}{\lambda_{1}^{6}} + \frac{720}{\lambda_{1}^{7}} & - \frac{6}{\lambda_{1}^{2}} + \frac{180}{\lambda_{1}^{3}} - \frac{900}{\lambda_{1}^{4}} + \frac{1440}{\lambda_{1}^{5}} - \frac{720}{\lambda_{1}^{6}} & - \frac{15}{\lambda_{1}^{2}} + \frac{210}{\lambda_{1}^{3}} - \frac{540}{\lambda_{1}^{4}} + \frac{360}{\lambda_{1}^{5}} & - \frac{20}{\lambda_{1}^{2}} + \frac{120}{\lambda_{1}^{3}} - \frac{120}{\lambda_{1}^{4}} & - \frac{15}{\lambda_{1}^{2}} + \frac{30}{\lambda_{1}^{3}} & - \frac{6}{\lambda_{1}^{2}} & \frac{1}{\lambda_{1}} & 0\\- \frac{1}{\lambda_{1}^{2}} + \frac{126}{\lambda_{1}^{3}} - \frac{1806}{\lambda_{1}^{4}} + \frac{8400}{\lambda_{1}^{5}} - \frac{16800}{\lambda_{1}^{6}} + \frac{15120}{\lambda_{1}^{7}} - \frac{5040}{\lambda_{1}^{8}} & - \frac{7}{\lambda_{1}^{2}} + \frac{434}{\lambda_{1}^{3}} - \frac{3780}{\lambda_{1}^{4}} + \frac{10920}{\lambda_{1}^{5}} - \frac{12600}{\lambda_{1}^{6}} + \frac{5040}{\lambda_{1}^{7}} & - \frac{21}{\lambda_{1}^{2}} + \frac{630}{\lambda_{1}^{3}} - \frac{3150}{\lambda_{1}^{4}} + \frac{5040}{\lambda_{1}^{5}} - \frac{2520}{\lambda_{1}^{6}} & - \frac{35}{\lambda_{1}^{2}} + \frac{490}{\lambda_{1}^{3}} - \frac{1260}{\lambda_{1}^{4}} + \frac{840}{\lambda_{1}^{5}} & - \frac{35}{\lambda_{1}^{2}} + \frac{210}{\lambda_{1}^{3}} - \frac{210}{\lambda_{1}^{4}} & - \frac{21}{\lambda_{1}^{2}} + \frac{42}{\lambda_{1}^{3}} & - \frac{7}{\lambda_{1}^{2}} & \frac{1}{\lambda_{1}}\end{matrix}\right]
\end{displaymath}
\fi
$\mathcal{P}^{-1} = X\,J^{-1}\,X^{-1}$, where
\begin{displaymath}
X_{\boldsymbol{\alpha}} = \alpha_{0} \left[\begin{matrix}1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\0 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\0 & 1 & 2 & 0 & 0 & 0 & 0 & 0\\0 & 1 & 6 & 6 & 0 & 0 & 0 & 0\\0 & 1 & 14 & 36 & 24 & 0 & 0 & 0\\0 & 1 & 30 & 150 & 240 & 120 & 0 & 0\\0 & 1 & 62 & 540 & 1560 & 1800 & 720 & 0\\0 & 1 & 126 & 1806 & 8400 & 16800 & 15120 & 5040\end{matrix}\right]
\end{displaymath}
with $\boldsymbol{\alpha} = \left[ \alpha_{0}, 0,0,0,0,0,0,0 \right]^{T}$, and
\begin{displaymath}
J^{-1} = \left[\begin{matrix}\frac{1}{\lambda_{1}} & 0 & 0 & 0 & 0 & 0 & 0 & 0\\- \frac{1}{\lambda_{1}^{2}} & \frac{1}{\lambda_{1}} & 0 & 0 & 0 & 0 & 0 & 0\\\frac{1}{\lambda_{1}^{3}} & - \frac{1}{\lambda_{1}^{2}} & \frac{1}{\lambda_{1}} & 0 & 0 & 0 & 0 & 0\\- \frac{1}{\lambda_{1}^{4}} & \frac{1}{\lambda_{1}^{3}} & - \frac{1}{\lambda_{1}^{2}} & \frac{1}{\lambda_{1}} & 0 & 0 & 0 & 0\\\frac{1}{\lambda_{1}^{5}} & - \frac{1}{\lambda_{1}^{4}} & \frac{1}{\lambda_{1}^{3}} & - \frac{1}{\lambda_{1}^{2}} & \frac{1}{\lambda_{1}} & 0 & 0 & 0\\- \frac{1}{\lambda_{1}^{6}} & \frac{1}{\lambda_{1}^{5}} & - \frac{1}{\lambda_{1}^{4}} & \frac{1}{\lambda_{1}^{3}} & - \frac{1}{\lambda_{1}^{2}} & \frac{1}{\lambda_{1}} & 0 & 0\\\frac{1}{\lambda_{1}^{7}} & - \frac{1}{\lambda_{1}^{6}} & \frac{1}{\lambda_{1}^{5}} & - \frac{1}{\lambda_{1}^{4}} & \frac{1}{\lambda_{1}^{3}} & - \frac{1}{\lambda_{1}^{2}} & \frac{1}{\lambda_{1}} & 0\\- \frac{1}{\lambda_{1}^{8}} & \frac{1}{\lambda_{1}^{7}} & - \frac{1}{\lambda_{1}^{6}} & \frac{1}{\lambda_{1}^{5}} & - \frac{1}{\lambda_{1}^{4}} & \frac{1}{\lambda_{1}^{3}} & - \frac{1}{\lambda_{1}^{2}} & \frac{1}{\lambda_{1}}\end{matrix}\right]
\end{displaymath}


Finally, let $A \sim_{X} J$ and $B \sim_{Y} J$, for any two Riordan arrays $A$ and $B$, then
\begin{displaymath}
    X^{-1}\,A\,X = Y^{-1}\,B\,Y \quad\rightarrow\quad A \sim_{X\,Y^{-1}} B
\end{displaymath}
because $Y\,X^{-1}\,A\,X\,Y^{-1} = B$; moreover, $f(A) \sim_{X\,Y^{-1}} f(B)$
also holds, for any function $f$ defined on $\sigma(A)$. For the sake of
clarity, $\mathcal{P} \sim_{X_{\boldsymbol{\alpha}}\,\left(Y_{\boldsymbol{\beta}}\right)^{-1}}\mathcal{C}$ holds
because of
\begin{displaymath}
Y_{\boldsymbol{\beta}} = \beta_{0} \left[\begin{matrix}1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\0 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\0 & 2 & 2 & 0 & 0 & 0 & 0 & 0\\0 & 5 & 11 & 6 & 0 & 0 & 0 & 0\\0 & 14 & 52 & 62 & 24 & 0 & 0 & 0\\0 & 42 & 238 & 470 & 394 & 120 & 0 & 0\\0 & 132 & 1084 & 3176 & 4348 & 2844 & 720 & 0\\0 & 429 & 4956 & 20323 & 40562 & 42874 & 23148 & 5040\end{matrix}\right]
\end{displaymath}
with $\boldsymbol{\beta} = \left[ \beta_{0}, 0,0,0,0,0,0,0 \right]^{T}$, and
\begin{displaymath}
{X_{\boldsymbol{\alpha}}\,\left(Y_{\boldsymbol{\beta}}\right)^{-1}} = \frac{\alpha_{0}}{\beta_{0}} \left[\begin{matrix}1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\0 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\0 & -1 & 1 & 0 & 0 & 0 & 0 & 0\\0 & 1 & - \frac{5}{2} & 1 & 0 & 0 & 0 & 0\\0 & -1 & \frac{29}{6} & - \frac{13}{3} & 1 & 0 & 0 & 0\\0 & 1 & - \frac{613}{72} & \frac{467}{36} & - \frac{77}{12} & 1 & 0 & 0\\0 & -1 & \frac{10331}{720} & - \frac{11989}{360} & \frac{3199}{120} & - \frac{87}{10} & 1 & 0\\0 & 1 & - \frac{1019899}{43200} & \frac{1701701}{21600} & - \frac{656591}{7200} & \frac{28183}{600} & - \frac{223}{20} & 1\end{matrix}\right]
\end{displaymath}
provided that both $\mathcal{P}\sim_{X_{\boldsymbol{\alpha}}}J$ and $\mathcal{C}\sim_{Y_{\boldsymbol{\beta}}}J$ holds. On the other hand,
$\mathcal{C} \sim_{Y_{\boldsymbol{\beta}}\,\left(X_{\boldsymbol{\alpha}}\right)^{-1}}\mathcal{P}$, where
\begin{displaymath}
{Y_{\boldsymbol{\beta}}\,\left(X_{\boldsymbol{\alpha}}\right)^{-1}} = \frac{\beta_{0}}{\alpha_{0}} \left[\begin{matrix}1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\0 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\0 & 1 & 1 & 0 & 0 & 0 & 0 & 0\\0 & \frac{3}{2} & \frac{5}{2} & 1 & 0 & 0 & 0 & 0\\0 & \frac{8}{3} & 6 & \frac{13}{3} & 1 & 0 & 0 & 0\\0 & \frac{31}{6} & \frac{175}{12} & \frac{89}{6} & \frac{77}{12} & 1 & 0 & 0\\0 & \frac{157}{15} & \frac{215}{6} & \frac{281}{6} & \frac{175}{6} & \frac{87}{10} & 1 & 0\\0 & \frac{649}{30} & \frac{1767}{20} & \frac{851}{6} & 115 & \frac{1501}{30} & \frac{223}{20} & 1\end{matrix}\right]
\end{displaymath}
as required.





